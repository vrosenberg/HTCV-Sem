{
  "cells": [
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\nimport shutil\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport json\n\nfrom sklearn.metrics import confusion_matrix\nfrom PIL import Image",
      "metadata": {
        "id": "a29GnZIfdeuL",
        "cell_id": "0f32548964af44f1ba0acd4f96cb6469",
        "source_hash": "48f79535",
        "execution_start": 1685014006712,
        "execution_millis": 1,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "#from google.colab import drive\n#drive.mount('/content/drive')\n#",
      "metadata": {
        "id": "wzrqvryVd0Pf",
        "cell_id": "8829776d0c234158bdff1607566571f3",
        "source_hash": "5274cba9",
        "execution_start": 1685014007693,
        "execution_millis": 9,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "# Mappings for utility\nMAP_PERCENT_TO_AMOUNT = {\n    \"10\" : 280,\n    \"25\" : 700,\n    \"50\" : 1400,\n    \"100\": 2799\n}\n\nDAMAGE_LEVEL_TO_SCORE = {\n    \"destroyed\" : 4,\n    \"major-damage\" : 3,\n    \"minor-damage\" : 2,\n    \"no-damage\" : 1,\n}\n\nPERCENT = \"100\"\nTRAIN_SET_SIZE = MAP_PERCENT_TO_AMOUNT[PERCENT]",
      "metadata": {
        "id": "DjW1R0s2deuN",
        "cell_id": "e2b43ba5f0f84e4083e4a0eedf854b3e",
        "source_hash": "23722508",
        "execution_start": 1685014008928,
        "execution_millis": 2,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "os.listdir()",
      "metadata": {
        "id": "3s-OW6V0eK13",
        "cell_id": "7acec0c7b1fb436c8b6a05cf1f818aa0",
        "source_hash": "99b2ca84",
        "execution_start": 1685014011476,
        "execution_millis": 5,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "[]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "DATASET_FOLDER_PATH = \"/datasets/xviewdataset/HTCV-Sem/dataset/\"\nXVIEW2_TXT_FILE = \"/datasets/xviewdataset/HTCV-Sem/dataset/xview2.txt\"\nMODEL_OUTPUT_FILENAME = \"model_deepnote_test\"",
      "metadata": {
        "id": "PN0-MvlcdeuO",
        "cell_id": "632f5d87229f409c874ee69c8969988d",
        "source_hash": "5258c29a",
        "execution_start": 1685014043874,
        "execution_millis": 2,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "!ls /datasets/xviewdataset/HTCV-Sem/dataset/",
      "metadata": {
        "cell_id": "dc74046fea604b12b754d65ef62238cb",
        "source_hash": "e4744247",
        "execution_start": 1685014012884,
        "execution_millis": 687,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "hold  test  train  xview2.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Baseline model\nclass ResNetClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(ResNetClassifier, self).__init__()\n        self.resnet = models.resnet18(weights=None)\n        self.resnet.fc = nn.Linear(512, num_classes)\n\n        \n\n    def forward(self, x):\n        x = self.resnet(x)\n        return x\n    \n    def train_model(self, dataloader, num_epochs, lr, momentum):\n        self.train()\n        self.to(device)\n\n        optimizer = torch.optim.SGD(self.parameters(), lr, momentum)\n        criterion = nn.CrossEntropyLoss()\n        # Train the model\n\n        for epoch in range(num_epochs):\n            running_loss = 0.0\n            for images, labels in dataloader:\n                images, labels =  images.to(device),labels.to(device)\n                \n                optimizer.zero_grad()\n\n                # Forward pass\n                outputs = self(images)\n                loss = criterion(outputs, labels)\n\n                # Backward pass and optimizatio.n\n                loss.backward()\n                optimizer.step()\n\n                running_loss += loss.item()\n\n            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}\")\n        torch.save(self.state_dict(), MODEL_OUTPUT_FILENAME + '.pth')\n    # Define the evaluation function\n    def evaluate_model(self, test_dataloader):\n        self.eval()  # Set the model to evaluation mode\n        self.to(device)\n\n        correct = 0\n        total = 0\n\n        true_labels = []\n        predicted_labels = []\n\n        with torch.no_grad():\n            for images, labels in test_dataloader:\n                images = images.to(device)\n                labels = labels.to(device)\n\n                outputs = self(images)\n                _, predicted = torch.max(outputs.data, 1)\n\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                true_labels.extend(labels.cpu().numpy())\n                predicted_labels.extend(predicted.cpu().numpy())\n\n        accuracy = correct / total\n        confusion_mat = confusion_matrix(true_labels, predicted_labels, normalize=\"true\")\n\n\n        return accuracy, confusion_mat",
      "metadata": {
        "id": "DlES_LUSdeuO",
        "cell_id": "248807e634d34b35a576fe10386c0912",
        "source_hash": "bdbb3d8a",
        "execution_start": 1685014013607,
        "execution_millis": 6,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "# Get predefined training samples for the seminar\ndef get_training_set_entries(amount=280):\n    xview_file = open(XVIEW2_TXT_FILE,'r')\n    return xview_file.read().splitlines()[:amount]",
      "metadata": {
        "id": "_wHERJXgdeuP",
        "cell_id": "cc7830f0ed524fb093079e3fc14693a2",
        "source_hash": "68cfcd9a",
        "execution_start": 1685014015616,
        "execution_millis": 4,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "# Get mean and standard deviation of dataset\n# This is needed for normalization\ndef calc_mean_and_std_of_dataset(loader):\n    mean = 0.0\n    std = 0.0\n    total_samples = 0\n\n    for images, _ in loader:\n        batch_samples = images.size(0)\n        images = images.view(batch_samples, images.size(1), -1)\n        mean += images.mean(2).sum(0)\n        std += images.std(2).sum(0)\n        total_samples += batch_samples\n\n    mean /= total_samples\n    std /= total_samples\n    \n    return mean, std",
      "metadata": {
        "id": "l0H_7LJudeuP",
        "cell_id": "52e63fff2fc24c48a5ee9615d3018933",
        "source_hash": "1843f377",
        "execution_start": 1685014017424,
        "execution_millis": 5,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "Normalize Dataset",
      "metadata": {
        "id": "J1eCj5HAdeuP",
        "cell_id": "e2287b8ce4524fc6a194ef5f774d0103",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "# Load and preprocess your dataset using torchvision.transforms\npre_norm_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize the input image to match the expected size of ResNet (224x224)\n    transforms.ToTensor()\n])\n# Calculate the mean and standard deviation of your dataset\npath_to_dataset = os.path.join(DATASET_FOLDER_PATH,\"train\")\ndataset = torchvision.datasets.ImageFolder(path_to_dataset, transform=pre_norm_transform)\ndata_point_names = get_training_set_entries(amount = TRAIN_SET_SIZE)\n\nsubset = [dataset[dataset.imgs.index((file_path, class_label))] for file_path, class_label in dataset.imgs if os.path.basename(file_path) in data_point_names]\nloader = torch.utils.data.DataLoader(subset, batch_size=32, shuffle=False)\n\nmean, std = calc_mean_and_std_of_dataset(loader=loader)",
      "metadata": {
        "id": "fn5BpbUddeuQ",
        "cell_id": "7409b7bad3714c94b5aa73472a419d99",
        "source_hash": "6f7bea66",
        "execution_start": 1685014049020,
        "execution_millis": 120,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "Setup training model",
      "metadata": {
        "id": "8pOMod89deuQ",
        "cell_id": "17bd5b27779347e7ac8880fbdbad0bed",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "\n\n# Update the normalization transform using your dataset's mean and standard deviation\ntransform = transforms.Compose([\n    pre_norm_transform,\n    transforms.Normalize(mean, std)\n])\n\n# Example dataset loading using torchvision.datasets.ImageFolder\ndataset = torchvision.datasets.ImageFolder(path_to_dataset, transform=transform)\nsubset = [dataset[dataset.imgs.index((file_path, class_label))] for file_path, class_label in dataset.imgs if os.path.basename(file_path) in data_point_names]\ndataloader = torch.utils.data.DataLoader(subset, batch_size=32, shuffle=True)",
      "metadata": {
        "id": "ETDKZS-ideuQ",
        "cell_id": "897e0dfb152a41f18894c41f3caa49ea",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Train model",
      "metadata": {
        "id": "rTzIxsmYdeuR",
        "cell_id": "9282d71c742041f4a6f3d9030786d723",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "# Train the model\nnum_classes = 5  # Number of output classes\n\nnum_epochs=50\nlr=0.01\nmomentum=0.9\nmodel = ResNetClassifier(num_classes)\n\nmodel.train_model(dataloader, num_epochs, lr, momentum)\n",
      "metadata": {
        "id": "HmA8mz_UdeuR",
        "cell_id": "c4316131f052442fb2ceebc7234155d6",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Setup evaluating test performance",
      "metadata": {
        "id": "Il1MBF6SdeuR",
        "cell_id": "233aca035ae643a7b181b614e329ff65",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "test_dataset = torchvision.datasets.ImageFolder(os.path.join(DATASET_FOLDER_PATH, \"test\"), transform=transform)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=2, pin_memory=True)",
      "metadata": {
        "id": "c02HwsKUdeuR",
        "cell_id": "a8eb364cd1034306bce244d97fe24cd3",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Evaluate model on test data",
      "metadata": {
        "id": "3Llj15MBdeuS",
        "cell_id": "c14c7a11032945bd90792af8505e1fd7",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "\nLOAD_MODEL = False\nLOAD_MODEL_PATH = 'resnet_classifier.pth'\n#Load the saved model state dictionary\nif(LOAD_MODEL):\n  model = ResNetClassifier(num_classes)\n  model.load_state_dict(torch.load('resnet_classifier.pth'))\n\n# Evaluate the model\naccuracy, confusion_mat = model.evaluate_model(test_dataloader=test_dataloader)\n\n# Print the accuracy\nprint(f\"Accuracy: {accuracy}\")\n\nprint(\"Confusion Matrix:\")\nprint(confusion_mat)\n",
      "metadata": {
        "id": "nsDTzwi8deuS",
        "cell_id": "f59fb3d01700449e96d9a1a8f3d350de",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "mean_val = [mean_i.item() for mean_i in mean]\nstd_val = [std_i.item() for std_i in std]\ndata_info = {\n    'dataset_size' : MAP_PERCENT_TO_AMOUNT[PERCENT],\n    'mean_0' : mean.[0],\n    'mean_1' : mean_val[1],\n    'mean_2' : mean_val[2],\n    'standard_dev_0' : std_val[0],\n    'standard_dev_1' : std_val[1],\n    'standard_dev_2' : std_val[2]\n}\nmodel_info = {\n    'dataset_size' : MAP_PERCENT_TO_AMOUNT[PERCENT],\n    'architecture' : \"resnet18\",\n    'learning_rate': lr,\n    'batch_size': 32,\n    'num_epochs': num_epochs,\n    'momentum' : momentum,\n    'accuracy' : accuracy,\n    'confusion_mat' : confusion_mat.tolist()\n}\nwith open(\"dataset_size_\" + str(MAP_PERCENT_TO_AMOUNT[PERCENT]) +'.json', 'w') as file:\n    json.dump(data_info, file)\n\nwith open(MODEL_OUTPUT_FILENAME +'.json', 'w') as file:\n    json.dump(model_info, file)",
      "metadata": {
        "id": "TGljGznc5w8g",
        "cell_id": "7df6ff2928964b7cb9b0ca8dc9870db1",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Visualize Results",
      "metadata": {
        "id": "dBxQcEc-deuS",
        "cell_id": "f0d3346ff81d4b66a2ba95bc7ffc1166",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "# Get the class labels\nclass_labels = test_dataset.classes\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the confusion matrix\nsns.heatmap(confusion_mat, annot=True, fmt=\".3f\", cmap=\"Blues\", cbar=False,\n            xticklabels=class_labels, yticklabels=class_labels, ax=ax)\n\n# Set labels and title\nax.set_xlabel(\"Predicted Labels\")\nax.set_ylabel(\"True Labels\")\nax.set_title(\"Confusion Matrix\")\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=45)\n\n# Display the plot\nplt.show()",
      "metadata": {
        "id": "wFmSOI-ideuS",
        "cell_id": "16e7c8fa18914e4c94f8ca460a0601f2",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ac044641-96a0-4e06-ae59-4421e551585a' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "deepnote": {},
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    },
    "orig_nbformat": 4,
    "deepnote_notebook_id": "f7a42fbfe0fd4b20ae96bc3c8d717607",
    "deepnote_execution_queue": []
  }
}