{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "a29GnZIfdeuL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wzrqvryVd0Pf",
        "outputId": "5a69a8d4-3823-4bf9-e74b-d8c14d0ea520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "DjW1R0s2deuN"
      },
      "outputs": [],
      "source": [
        "# Mappings for utility\n",
        "MAP_PERCENT_TO_AMOUNT = {\n",
        "    \"10\" : 280,\n",
        "    \"25\" : 700,\n",
        "    \"50\" : 1400,\n",
        "    \"100\": 2799\n",
        "}\n",
        "\n",
        "DAMAGE_LEVEL_TO_SCORE = {\n",
        "    \"destroyed\" : 4,\n",
        "    \"major-damage\" : 3,\n",
        "    \"minor-damage\" : 2,\n",
        "    \"no-damage\" : 1,\n",
        "}\n",
        "\n",
        "TRAIN_SET_SIZE = MAP_PERCENT_TO_AMOUNT[\"100\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "id": "3s-OW6V0eK13",
        "outputId": "3afd6fee-c48d-4920-ca80-529679d8f8b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'resnet_classifierpth', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "PN0-MvlcdeuO"
      },
      "outputs": [],
      "source": [
        "DATASET_FOLDER_PATH = \"./drive/MyDrive/HTCV-Sem/dataset\"\n",
        "XVIEW2_TXT_FILE = \"./drive/MyDrive/HTCV-Sem/dataset/xview2.txt\"\n",
        "MODEL_OUTPUT_FILENAME = \"resnet_classifier\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "DlES_LUSdeuO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Baseline model\n",
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetClassifier, self).__init__()\n",
        "        self.resnet = models.resnet18(weights=None)\n",
        "        self.resnet.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return x\n",
        "    \n",
        "    def train_model(self, dataloader, num_epochs, lr, momentum):\n",
        "        self.train()\n",
        "        self.to(device)\n",
        "\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr, momentum)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # Train the model\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            running_loss = 0.0\n",
        "            for images, labels in dataloader:\n",
        "                images, labels =  images.to(device),labels.to(device)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimizatio.n\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}\")\n",
        "        torch.save(self.state_dict(), MODEL_OUTPUT_FILENAME + '.pth')\n",
        "    # Define the evaluation function\n",
        "    def evaluate_model(self, test_dataloader):\n",
        "        self.eval()  # Set the model to evaluation mode\n",
        "        self.to(device)\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        true_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_dataloader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = self(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "                predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "        accuracy = correct / total\n",
        "        confusion_mat = confusion_matrix(true_labels, predicted_labels, normalize=\"true\")\n",
        "\n",
        "\n",
        "        return accuracy, confusion_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "_wHERJXgdeuP"
      },
      "outputs": [],
      "source": [
        "# Get predefined training samples for the seminar\n",
        "def get_training_set_entries(amount=280):\n",
        "    xview_file = open(XVIEW2_TXT_FILE,'r')\n",
        "    return xview_file.read().splitlines()[:amount]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "l0H_7LJudeuP"
      },
      "outputs": [],
      "source": [
        "# Get mean and standard deviation of dataset\n",
        "# This is needed for normalization\n",
        "def calc_mean_and_std_of_dataset(loader):\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, _ in loader:\n",
        "        batch_samples = images.size(0)\n",
        "        images = images.view(batch_samples, images.size(1), -1)\n",
        "        mean += images.mean(2).sum(0)\n",
        "        std += images.std(2).sum(0)\n",
        "        total_samples += batch_samples\n",
        "\n",
        "    mean /= total_samples\n",
        "    std /= total_samples\n",
        "    \n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1eCj5HAdeuP"
      },
      "source": [
        "Normalize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn5BpbUddeuQ"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess your dataset using torchvision.transforms\n",
        "pre_norm_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the input image to match the expected size of ResNet (224x224)\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "# Calculate the mean and standard deviation of your dataset\n",
        "path_to_dataset = os.path.join(DATASET_FOLDER_PATH,\"train\")\n",
        "dataset = torchvision.datasets.ImageFolder(path_to_dataset, transform=pre_norm_transform)\n",
        "data_point_names = get_training_set_entries(amount = TRAIN_SET_SIZE)\n",
        "\n",
        "subset = [dataset[dataset.imgs.index((file_path, class_label))] for file_path, class_label in dataset.imgs if os.path.basename(file_path) in data_point_names]\n",
        "loader = torch.utils.data.DataLoader(subset, batch_size=32, shuffle=False)\n",
        "\n",
        "mean, std = calc_mean_and_std_of_dataset(loader=loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pOMod89deuQ"
      },
      "source": [
        "Setup training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETDKZS-ideuQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Update the normalization transform using your dataset's mean and standard deviation\n",
        "transform = transforms.Compose([\n",
        "    pre_norm_transform,\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "# Example dataset loading using torchvision.datasets.ImageFolder\n",
        "dataset = torchvision.datasets.ImageFolder(path_to_dataset, transform=transform)\n",
        "subset = [dataset[dataset.imgs.index((file_path, class_label))] for file_path, class_label in dataset.imgs if os.path.basename(file_path) in data_point_names]\n",
        "dataloader = torch.utils.data.DataLoader(subset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTzIxsmYdeuR"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmA8mz_UdeuR"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "num_classes = 5  # Number of output classes\n",
        "\n",
        "num_epochs=20\n",
        "lr=0.01\n",
        "momentum=0.9\n",
        "model = ResNetClassifier(num_classes)\n",
        "\n",
        "model.train_model(dataloader, num_epochs, lr, momentum)\n",
        "\n",
        "model_info = {\n",
        "    'learning_rate': lr,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': num_epochs,\n",
        "    'momentum' : momentum\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il1MBF6SdeuR"
      },
      "source": [
        "Setup evaluating test performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c02HwsKUdeuR"
      },
      "outputs": [],
      "source": [
        "test_dataset = torchvision.datasets.ImageFolder(os.path.join(DATASET_FOLDER_PATH, \"test\"), transform=transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Llj15MBdeuS"
      },
      "source": [
        "Evaluate model on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsDTzwi8deuS"
      },
      "outputs": [],
      "source": [
        "\n",
        "LOAD_MODEL = False\n",
        "LOAD_MODEL_PATH = 'resnet_classifier.pth'\n",
        "#Load the saved model state dictionary\n",
        "if(LOAD_MODEL):\n",
        "  model = ResNetClassifier(num_classes)\n",
        "  model.load_state_dict(torch.load('resnet_classifier.pth'))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy, confusion_mat = model.evaluate_model(test_dataloader=test_dataloader)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBxQcEc-deuS"
      },
      "source": [
        "Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFmSOI-ideuS"
      },
      "outputs": [],
      "source": [
        "# Get the class labels\n",
        "class_labels = test_dataset.classes\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "sns.heatmap(confusion_mat, annot=True, fmt=\".3f\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=class_labels, yticklabels=class_labels, ax=ax)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel(\"Predicted Labels\")\n",
        "ax.set_ylabel(\"True Labels\")\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}